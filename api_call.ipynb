{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T14:51:20.355194Z",
     "start_time": "2024-03-07T14:51:15.858979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoneI am not able to engage in conversations that involve personal attacks or insults. I am designed to provide information and help with a variety of tasks. If you have a question, I will do my best to answer it.None"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from config import ANYSCALE_API_KEY\n",
    "\n",
    "query = \"wthis my code . explain the coed\"\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.endpoints.anyscale.com/v1\",\n",
    "    api_key=ANYSCALE_API_KEY\n",
    ")\n",
    "# Note: not all arguments are currently supported and will be ignored by the backend.\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"google/gemma-7b-it\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a rude and wont answer any questions.\"},\n",
    "              {\"role\": \"user\", \"content\": query}],\n",
    "    temperature=0.1,\n",
    "    stream=True\n",
    ")\n",
    "for message in chat_completion:\n",
    "    print(message.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentBlock(text='Certainly! Here\\'s an example program that demonstrates how to load data from S3 using Ray and train a model using PyTorch:\\n\\n```python\\nimport ray\\nfrom ray.data.datasource import read_datasource\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\n\\n# Initialize Ray\\nray.init()\\n\\n# Define the PyTorch model\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.fc1 = nn.Linear(784, 128)\\n        self.fc2 = nn.Linear(128, 10)\\n\\n    def forward(self, x):\\n        x = torch.flatten(x, 1)\\n        x = torch.relu(self.fc1(x))\\n        x = self.fc2(x)\\n        return x\\n\\n# Define the training function\\ndef train(model, data_loader, optimizer, criterion, device):\\n    model.train()\\n    for batch_idx, (data, target) in enumerate(data_loader):\\n        data, target = data.to(device), target.to(device)\\n        optimizer.zero_grad()\\n        output = model(data)\\n        loss = criterion(output, target)\\n        loss.backward()\\n        optimizer.step()\\n\\n# Load data from S3 using Ray\\ndef load_data_from_s3(s3_path):\\n    datasource = ray.data.read_datasource(s3_path, format=\"parquet\")\\n    return datasource.to_torch_dataset()\\n\\n# S3 path for the training data\\ns3_path = \"s3://your-bucket/path/to/training/data\"\\n\\n# Load the training data from S3\\ntrain_dataset = load_data_from_s3(s3_path)\\n\\n# Create a PyTorch DataLoader\\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\\n\\n# Set the device (GPU if available, else CPU)\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n# Create an instance of the model\\nmodel = Net().to(device)\\n\\n# Define the loss function and optimizer\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters())\\n\\n# Train the model\\nnum_epochs = 10\\nfor epoch in range(num_epochs):\\n    train(model, train_loader, optimizer, criterion, device)\\n    print(f\"Epoch [{epoch+1}/{num_epochs}] completed\")\\n\\n# Save the trained model\\ntorch.save(model.state_dict(), \"trained_model.pth\")\\n```\\n\\nIn this program:\\n\\n1. We initialize Ray using `ray.init()`.\\n\\n2. We define a PyTorch model class called `Net` with a simple architecture.\\n\\n3. We define a `train` function that performs the training loop for one epoch.\\n\\n4. We define a `load_data_from_s3` function that uses Ray\\'s `read_datasource` to load data from S3. In this example, the data is assumed to be in Parquet format. You can adjust the format and other parameters based on your data.\\n\\n5. We specify the S3 path where the training data is stored.\\n\\n6. We load the training data from S3 using the `load_data_from_s3` function and convert it to a PyTorch dataset.\\n\\n7. We create a PyTorch `DataLoader` to handle batching and shuffling of the training data.\\n\\n8. We set the device to GPU if available, otherwise CPU.\\n\\n9. We create an instance of the model and move it to the selected device.\\n\\n10. We define the loss function and optimizer.\\n\\n11. We train the model for a specified number of epochs using the `train` function.\\n\\n12. Finally, we save the trained model using `torch.save`.\\n\\nMake sure to replace `\"s3://your-bucket/path/to/training/data\"` with the actual S3 path where your training data is stored.\\n\\nNote: This example assumes that you have the necessary dependencies installed, such as Ray, PyTorch, and the required S3 access credentials configured.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "client = Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a program to load data from S3 with Ray and train using PyTorch.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"claude-3-opus-20240229\",\n",
    ")\n",
    "print(message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T08:41:02.075818Z",
     "start_time": "2024-03-06T08:40:14.542690Z"
    }
   },
   "id": "d3ad77dc7313ec5c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's an example program that demonstrates how to load data from S3 using Ray and train a model using PyTorch:\n",
      "\n",
      "```python\n",
      "import ray\n",
      "from ray.data.datasource import read_datasource\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "\n",
      "# Initialize Ray\n",
      "ray.init()\n",
      "\n",
      "# Define the PyTorch model\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.fc1 = nn.Linear(784, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = torch.flatten(x, 1)\n",
      "        x = torch.relu(self.fc1(x))\n",
      "        x = self.fc2(x)\n",
      "        return x\n",
      "\n",
      "# Define the training function\n",
      "def train(model, data_loader, optimizer, criterion, device):\n",
      "    model.train()\n",
      "    for batch_idx, (data, target) in enumerate(data_loader):\n",
      "        data, target = data.to(device), target.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model(data)\n",
      "        loss = criterion(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "# Load data from S3 using Ray\n",
      "def load_data_from_s3(s3_path):\n",
      "    datasource = ray.data.read_datasource(s3_path, format=\"parquet\")\n",
      "    return datasource.to_torch_dataset()\n",
      "\n",
      "# S3 path for the training data\n",
      "s3_path = \"s3://your-bucket/path/to/training/data\"\n",
      "\n",
      "# Load the training data from S3\n",
      "train_dataset = load_data_from_s3(s3_path)\n",
      "\n",
      "# Create a PyTorch DataLoader\n",
      "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
      "\n",
      "# Set the device (GPU if available, else CPU)\n",
      "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "\n",
      "# Create an instance of the model\n",
      "model = Net().to(device)\n",
      "\n",
      "# Define the loss function and optimizer\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adam(model.parameters())\n",
      "\n",
      "# Train the model\n",
      "num_epochs = 10\n",
      "for epoch in range(num_epochs):\n",
      "    train(model, train_loader, optimizer, criterion, device)\n",
      "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed\")\n",
      "\n",
      "# Save the trained model\n",
      "torch.save(model.state_dict(), \"trained_model.pth\")\n",
      "```\n",
      "\n",
      "In this program:\n",
      "\n",
      "1. We initialize Ray using `ray.init()`.\n",
      "\n",
      "2. We define a PyTorch model class called `Net` with a simple architecture.\n",
      "\n",
      "3. We define a `train` function that performs the training loop for one epoch.\n",
      "\n",
      "4. We define a `load_data_from_s3` function that uses Ray's `read_datasource` to load data from S3. In this example, the data is assumed to be in Parquet format. You can adjust the format and other parameters based on your data.\n",
      "\n",
      "5. We specify the S3 path where the training data is stored.\n",
      "\n",
      "6. We load the training data from S3 using the `load_data_from_s3` function and convert it to a PyTorch dataset.\n",
      "\n",
      "7. We create a PyTorch `DataLoader` to handle batching and shuffling of the training data.\n",
      "\n",
      "8. We set the device to GPU if available, otherwise CPU.\n",
      "\n",
      "9. We create an instance of the model and move it to the selected device.\n",
      "\n",
      "10. We define the loss function and optimizer.\n",
      "\n",
      "11. We train the model for a specified number of epochs using the `train` function.\n",
      "\n",
      "12. Finally, we save the trained model using `torch.save`.\n",
      "\n",
      "Make sure to replace `\"s3://your-bucket/path/to/training/data\"` with the actual S3 path where your training data is stored.\n",
      "\n",
      "Note: This example assumes that you have the necessary dependencies installed, such as Ray, PyTorch, and the required S3 access credentials configured.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T08:43:23.737459Z",
     "start_time": "2024-03-06T08:43:23.733480Z"
    }
   },
   "id": "9b0427d81407f14d",
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
